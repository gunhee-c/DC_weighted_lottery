{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\chorj\\anaconda3\\envs\\streamlit-app\\lib\\site-packages (4.19.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\chorj\\anaconda3\\envs\\streamlit-app\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.1.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\chorj\\anaconda3\\envs\\streamlit-app\\lib\\site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\chorj\\anaconda3\\envs\\streamlit-app\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\chorj\\anaconda3\\envs\\streamlit-app\\lib\\site-packages (from selenium) (2023.11.17)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\chorj\\anaconda3\\envs\\streamlit-app\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\chorj\\anaconda3\\envs\\streamlit-app\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\chorj\\anaconda3\\envs\\streamlit-app\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\chorj\\anaconda3\\envs\\streamlit-app\\lib\\site-packages (from trio~=0.17->selenium) (3.6)\n",
      "Requirement already satisfied: outcome in c:\\users\\chorj\\anaconda3\\envs\\streamlit-app\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\chorj\\anaconda3\\envs\\streamlit-app\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\chorj\\anaconda3\\envs\\streamlit-app\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\chorj\\anaconda3\\envs\\streamlit-app\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\chorj\\anaconda3\\envs\\streamlit-app\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\chorj\\anaconda3\\envs\\streamlit-app\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\chorj\\anaconda3\\envs\\streamlit-app\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\chorj\\anaconda3\\envs\\streamlit-app\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Request Soup 형성\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserPostData:\n",
    "    def __init__(self, user, user_id, title, date, posting_index):\n",
    "        self.user = user\n",
    "        self.user_id = user_id\n",
    "        self.title = title\n",
    "        self.date = date\n",
    "        self.posting_index = int(posting_index)\n",
    "\n",
    "    def get_user(self):\n",
    "        return self.user\n",
    "    def get_user_id(self): \n",
    "        return self.user_id\n",
    "    def get_date(self):\n",
    "        return self.date\n",
    "    def get_data_index(self):\n",
    "        return self.posting_index\n",
    "    def get_title(self):\n",
    "        return self.title[1:]\n",
    "    \n",
    "class UserPostDataList:\n",
    "    def __init__(self):\n",
    "        self.user_list = []\n",
    "        self.user_id_list = []\n",
    "        self.title_list = []\n",
    "        self.date_list = []\n",
    "        self.posting_index_list = []\n",
    "        #self.user_dict = {}\n",
    "        #self.user_posting_dict = {}\n",
    "        self.earliest_date = \"\"\n",
    "        self.latest_date = \"\"\n",
    "        self.min_posting_id = 0\n",
    "        self.max_posting_id = 0\n",
    "        self.length = 0\n",
    "\n",
    "    def add_user_post_data(self, user_post):\n",
    "        self.user_list.append(user_post.get_user())\n",
    "        self.user_id_list.append(user_post.get_user_id())\n",
    "        self.title_list.append(user_post.get_title())\n",
    "        self.date_list.append(user_post.get_date())\n",
    "        self.posting_index_list.append(user_post.get_data_index())\n",
    "        self.length += 1\n",
    "        return self\n",
    "    \n",
    "    def get_earliest_and_latest_date(self):\n",
    "        if self.date_list == []:\n",
    "            self.earliest_date = \"1999-01-01 00:00:00\"\n",
    "            self.latest_date = \"1999-01-01 23:39:39\"\n",
    "            return self\n",
    "        else:\n",
    "            self.earliest_date = self.date_list[self.length-1]\n",
    "            self.latest_date = self.date_list[0]    \n",
    "            return self\n",
    "\n",
    "    def get_earliest_and_latest_posting(self):\n",
    "        if self.posting_index_list == []:\n",
    "            self.min_posting_id = 0\n",
    "            self.max_posting_id = 0\n",
    "            return self\n",
    "        else:\n",
    "            self.min_posting_id = self.posting_index_list[self.length-1]\n",
    "            self.max_posting_id = self.posting_index_list[0]\n",
    "            return self\n",
    "\n",
    "    def compare(self, target_time, debug = False):\n",
    "        if debug == True:\n",
    "            print(\"Comparing \" + str(target_time) + \" with bound \" + str(self.earliest_date) + \" and \" + str(self.latest_date))\n",
    "        if target_time >= self.earliest_date and target_time <= self.latest_date:\n",
    "            return 0\n",
    "        elif target_time < self.earliest_date:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1  \n",
    "\n",
    "    def __add__(self, other_datalist, debug = False): #Adding UserPoistDataList\n",
    "        if self.length == 0:\n",
    "            self.user_list = other_datalist.user_list\n",
    "            self.user_id_list = other_datalist.user_id_list\n",
    "            self.title_list = other_datalist.title_list\n",
    "            self.date_list = other_datalist.date_list\n",
    "            self.posting_index_list = other_datalist.posting_index_list\n",
    "            self.length = other_datalist.length\n",
    "            self.earliest_date = other_datalist.earliest_date\n",
    "            self.latest_date = other_datalist.latest_date\n",
    "            self.min_posting_id = other_datalist.min_posting_id\n",
    "            self.max_posting_id = other_datalist.max_posting_id\n",
    "            return self\n",
    "        cut = 0\n",
    "        if debug == True:\n",
    "            print(\"Adding UserPostDataList of length \" +str(other_datalist.length))\n",
    "            print(\"current min_posting id: \" + str(self.min_posting_id))\n",
    "            print(\"other min_posting id: \" + str(other_datalist.min_posting_id))\n",
    "            print(\"current max_posting id: \" + str(self.max_posting_id))\n",
    "            print(\"other max_posting id: \" + str(other_datalist.max_posting_id))\n",
    "            \n",
    "        for i in range(other_datalist.length):\n",
    "            if other_datalist.posting_index_list[i] >= self.min_posting_id:\n",
    "                cut = i+1\n",
    "                print(\"We are cutting \" + str(cut))\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "        if cut == 0:\n",
    "            print(\"No cutting\")\n",
    "        self.user_list = self.user_list + other_datalist.user_list[cut:]\n",
    "        self.user_id_list = self.user_id_list + other_datalist.user_id_list[cut:]\n",
    "        self.title_list = self.title_list + other_datalist.title_list[cut:]\n",
    "        self.date_list = self.date_list + other_datalist.date_list[cut:]\n",
    "        self.posting_index_list = self.posting_index_list + other_datalist.posting_index_list[cut:]\n",
    "        self.length = self.length + other_datalist.length - cut\n",
    "        self.min_posting_id = other_datalist.min_posting_id\n",
    "        self.earliest_date = other_datalist.earliest_date\n",
    "        return self\n",
    "    \n",
    "    def get_user_post_data_list(self):\n",
    "        return self.user_post_data_list\n",
    "\n",
    "    def __str__(self, min = 0, max = 0, get_content = False):\n",
    "        print(\"Earliest Date: \" + str(self.earliest_date) + \", Latest Date: \" + str(self.latest_date))\n",
    "        print(\"Min Posting ID: \" + str(self.min_posting_id) + \", Max Posting ID: \" + str(self.max_posting_id) + \", Length: \" + str(self.length))\n",
    "        if get_content == True:\n",
    "            if max == 0:\n",
    "                max = self.length\n",
    "\n",
    "            for i in range(min, max):\n",
    "                print(\"Title: \" + str(self.title_list[i]))\n",
    "                print(\"ID: \" + str(self.user_list[i]) + \", \" + str(self.user_id_list[i]))\n",
    "                print(\"Index: \" + str(i) + \", posting_index: \" + str(self.posting_index_list[i]) + \", Date:\" + str(self.date_list[i]))\n",
    "                print()\n",
    "\n",
    "        #return \"UserPostDat: \" + str(self.user_list) + \", \" + str(self.user_id_list) + \", \" + str(self.title_list) + \", \" + str(self.date_list) + \", \" + str(self.posting_index_list)\n",
    "\n",
    "        return \"\"\n",
    "\n",
    "class UserPostDataDict:\n",
    "    def __init__(self, UserPostList):\n",
    "        self.userPostList = UserPostList\n",
    "        self.user_dict = {}\n",
    "        self.user_posting_dict = {}\n",
    "\n",
    "    def match_user_id_to_user_name(self):\n",
    "        for i in range(self.userPostList.length):\n",
    "            if self.userPostList.user_id_list[i] in self.user_dict:\n",
    "                if self.userPostList.user_list[i] not in self.user_dict[self.userPostList.user_id_list[i]]:\n",
    "                    self.user_dict[self.userPostList.user_id_list[i]].append(self.userPostList.user_list[i])\n",
    "            else:\n",
    "                self.user_dict[self.userPostList.user_id_list[i]] = [self.userPostList.user_list[i]]\n",
    "        return self\n",
    "    \n",
    "    def collect_user_activities_by_user_id(self):\n",
    "        for user_id in self.userPostList.user_id_list:\n",
    "            if user_id in self.user_posting_dict:\n",
    "                self.user_posting_dict[user_id] += 1\n",
    "            else:\n",
    "                self.user_posting_dict[user_id] = 1\n",
    "        return self\n",
    "    \n",
    "    def build(self):\n",
    "        self.match_user_id_to_user_name()\n",
    "        self.collect_user_activities_by_user_id()\n",
    "        return self\n",
    "\n",
    "    def search_user_id_by_user(self, user):\n",
    "        for key in self.user_dict:\n",
    "            if user in self.user_dict[key]:\n",
    "                return key\n",
    "        return -1\n",
    "    \n",
    "    def search_user_posing_count(self,user):\n",
    "        user_id = self.search_user_id_by_user(user)\n",
    "        if user_id == -1:\n",
    "            return 0\n",
    "        else:\n",
    "            return self.user_posting_dict[user_id]\n",
    "\n",
    "    def __str__(self):\n",
    "        print(\"User Dictionary: \" + str(self.user_dict))\n",
    "        print(\"User Posting Dictionary: \" + str(self.user_posting_dict))\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "user_agents = [\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36'\n",
    "    # Add more user agents as needed\n",
    "]\n",
    "\n",
    "# Randomly select a User-Agent\n",
    "\n",
    "def extractSoupfromURL(url):\n",
    "    random_user_agent = random.choice(user_agents)\n",
    "    print(random_user_agent)\n",
    "    headers = {\n",
    "        'User_Agent': random_user_agent\n",
    "    }\n",
    "    request = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(request.content, 'html.parser')\n",
    "    time_to_sleep = random.uniform(1, 3)\n",
    "    time.sleep(time_to_sleep)\n",
    "    print(time_to_sleep)\n",
    "    return request, soup\n",
    "\n",
    "def construct_url(gall_url, page_num):\n",
    "    return gall_url + \"&page=\" + str(page_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "#시간 범위 확인\n",
    "def is_date_in_range(date_str, start_date_str, end_date_str):\n",
    "    date = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n",
    "    if len(start_date_str) == 10:\n",
    "        start_date_str = start_date_str + \" 00:00:00\"\n",
    "    if len(end_date_str) == 10:\n",
    "        end_date_str = end_date_str + \" 23:59:59\"\n",
    "    start_date = datetime.strptime(start_date_str, '%Y-%m-%d %H:%M:%S')\n",
    "    end_date = datetime.strptime(end_date_str, '%Y-%m-%d %H:%M:%S')\n",
    "    end_date = end_date + timedelta(days=1, seconds=-1) # to 23:59:59\n",
    "    return start_date <= date <= end_date\n",
    "\n",
    "#공지 걸러내는 용도\n",
    "def is_Notification(soup):\n",
    "    if soup.find('td', class_ = \"gall_subject\").text == \"공지\":\n",
    "        #print(\"공지 발견\")\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#한 줄에서 user, user_id, date를 추출\n",
    "def get_userPostData_from_line(sample):\n",
    "    try:\n",
    "        user = sample.find('span', class_ = \"nickname in\").text\n",
    "        user_id = sample.find('td', class_ = \"gall_writer ub-writer\")['data-uid']\n",
    "    except:\n",
    "        title1 = sample.find('span', class_ = \"nickname\").text\n",
    "        title2 = sample.find('span', class_ = \"ip\").text\n",
    "        user = title1 + title2\n",
    "        user_id = user\n",
    "    #print(user)\n",
    "    #print(user_id)\n",
    "    title = sample.find('a').text\n",
    "    #print(title[1:])\n",
    "    date_raw = sample.find('td', class_ = \"gall_date\")\n",
    "    date = date_raw['title']\n",
    "    #print(date)\n",
    "    posting_index = sample.find('td', class_ = \"gall_num\").text\n",
    "    userPostData = UserPostData(user, user_id, title, date, posting_index)\n",
    "    return userPostData\n",
    "\n",
    "#특정 페이지에서 start_date, end_date내의 user, user_id의 리스트 추출\n",
    "\n",
    "def get_user_and_date_from_soup_list(soup_list, start_date = \"\", end_date = \"\"):\n",
    "    userPostDataList = UserPostDataList()\n",
    "    #date_list = []\n",
    "    for line in soup_list:\n",
    "        if is_Notification(line) is False:\n",
    "            UserPostData = get_userPostData_from_line(line)\n",
    "            if start_date != \"\" and end_date != \"\":\n",
    "                if is_date_in_range(UserPostData.get_date(), start_date, end_date):\n",
    "                    UserPostData = get_userPostData_from_line(line)\n",
    "                    userPostDataList.add_user_post_data(UserPostData)\n",
    "            else:\n",
    "                UserPostData = get_userPostData_from_line(line)\n",
    "                userPostDataList.add_user_post_data(UserPostData)\n",
    "    userPostDataList.get_earliest_and_latest_date()\n",
    "    userPostDataList.get_earliest_and_latest_posting()\n",
    "    return userPostDataList\n",
    "\n",
    "\n",
    "def get_soup_list_from_page(gall_name, page_num):\n",
    "    url = construct_url(gall_name, page_num)\n",
    "    print(url)\n",
    "    request, soup = extractSoupfromURL(url)\n",
    "    print(request.text)\n",
    "    soup_list = soup.find_all('tr', class_ = 'ub-content us-post')\n",
    "    return request, soup_list\n",
    "\n",
    "def concat_userPostDataList(userPostDataList_list):\n",
    "    userPostDataList = UserPostDataList()\n",
    "    for userPostDataList_append in userPostDataList_list:\n",
    "        userPostDataList = userPostDataList + userPostDataList_append\n",
    "    return userPostDataList\n",
    "\n",
    "\n",
    "\n",
    "#parse_user_list(user_id_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://gall.dcinside.com/mini/board/lists/?id=pumpitup&page=1\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\n",
      "1.4335511175506228\n",
      "\n",
      "https://gall.dcinside.com/mini/board/lists/?id=pumpitup&page=2\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\n",
      "2.9596731771942117\n",
      "\n",
      "https://gall.dcinside.com/mini/board/lists/?id=pumpitup&page=3\n",
      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\n",
      "2.389169155513251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "request, soup_list = get_soup_list_from_page(\"https://gall.dcinside.com/mini/board/lists/?id=pumpitup\", 1)\n",
    "request1, soup_list2 = get_soup_list_from_page(\"https://gall.dcinside.com/mini/board/lists/?id=pumpitup\", 2)\n",
    "request2, soup_list3 = get_soup_list_from_page(\"https://gall.dcinside.com/mini/board/lists/?id=pumpitup\", 3)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take1: \n",
      "Earliest Date: 1999-01-01 00:00:00, Latest Date: 1999-01-01 23:39:39\n",
      "Min Posting ID: 0, Max Posting ID: 0, Length: 0\n",
      "\n",
      "Take2: \n",
      "Earliest Date: 1999-01-01 00:00:00, Latest Date: 1999-01-01 23:39:39\n",
      "Min Posting ID: 0, Max Posting ID: 0, Length: 0\n",
      "\n",
      "Take3: \n",
      "Earliest Date: 1999-01-01 00:00:00, Latest Date: 1999-01-01 23:39:39\n",
      "Min Posting ID: 0, Max Posting ID: 0, Length: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_userPostDataList1 = get_user_and_date_from_soup_list(soup_list, '2024-03-31', '2024-04-02')\n",
    "sample_userPostDataList2 = get_user_and_date_from_soup_list(soup_list2, '2024-03-31', '2024-04-02')\n",
    "sample_userPostDataList3 = get_user_and_date_from_soup_list(soup_list3, '2024-03-31', '2024-04-02')\n",
    "\n",
    "\n",
    "#\n",
    "print(\"Take1: \")\n",
    "print(sample_userPostDataList1)\n",
    "print(\"Take2: \")\n",
    "print(sample_userPostDataList2)\n",
    "print(\"Take3: \")\n",
    "print(sample_userPostDataList3)\n",
    "#print(\"SUM: \")\n",
    "#print(sample_userPostDataList)\n",
    " #'2024-03-31', '2024-04-02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest Date: 1999-01-01 00:00:00, Latest Date: 1999-01-01 23:39:39\n",
      "Min Posting ID: 0, Max Posting ID: 0, Length: 0\n",
      "\n",
      "Earliest Date: 1999-01-01 00:00:00, Latest Date: 1999-01-01 23:39:39\n",
      "Min Posting ID: 0, Max Posting ID: 0, Length: 0\n",
      "\n",
      "Earliest Date: 1999-01-01 00:00:00, Latest Date: 1999-01-01 23:39:39\n",
      "Min Posting ID: 0, Max Posting ID: 0, Length: 0\n",
      "\n",
      "Earliest Date: 1999-01-01 00:00:00, Latest Date: 1999-01-01 23:39:39\n",
      "Min Posting ID: 0, Max Posting ID: 0, Length: 0\n",
      "\n",
      "Earliest Date: 1999-01-01 00:00:00, Latest Date: 1999-01-01 23:39:39\n",
      "Min Posting ID: 0, Max Posting ID: 0, Length: 0\n",
      "\n",
      "Earliest Date: 1999-01-01 00:00:00, Latest Date: 1999-01-01 23:39:39\n",
      "Min Posting ID: 0, Max Posting ID: 0, Length: 0\n",
      "\n",
      "Earliest Date: 1999-01-01 00:00:00, Latest Date: 1999-01-01 23:39:39\n",
      "Min Posting ID: 0, Max Posting ID: 0, Length: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sample_userPostDataList1)\n",
    "print(sample_userPostDataList2)\n",
    "print(sample_userPostDataList3)\n",
    "\n",
    "sample2 = concat_userPostDataList([sample_userPostDataList1, sample_userPostDataList2, sample_userPostDataList3])\n",
    "\n",
    "print(sample_userPostDataList1)\n",
    "print(sample_userPostDataList2)\n",
    "print(sample_userPostDataList3)\n",
    "print(sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Dictionary: {}\n",
      "User Posting Dictionary: {}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userPostDataDict = UserPostDataDict(sample2)\n",
    "userPostDataDict.build()\n",
    "\n",
    "print(userPostDataDict)\n",
    "\n",
    "userPostDataDict.search_user_id_by_user(\"채은서\")\n",
    "#userPostDataDict.search_user_posing_count(\"앙기무띠\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "#유저 ID별 활동량을 저장함\n",
    "def collect_user_activities_by_user_id(user_id_dict, user_list):\n",
    "    #user_dict = {}\n",
    "    for user in user_list:\n",
    "        #print(user_dict)\n",
    "        if user in user_id_dict:\n",
    "            user_id_dict[user] += 1\n",
    "        else:\n",
    "            user_id_dict[user] = 1\n",
    "    return user_id_dict\n",
    "\n",
    "\n",
    "def do_binary_search_page(gall_name, min_page, max_page, target_date):\n",
    "    if max_page < min_page:\n",
    "        return -1\n",
    "    mid_page = (max_page + min_page) // 2\n",
    "    print(\"iterating:\" + str(mid_page))\n",
    "    is_soup_found = False\n",
    "    while(is_soup_found == False):\n",
    "        soup_list = get_soup_list_from_page(gall_name, str(mid_page))\n",
    "        sample_data = get_user_and_date_from_soup_list(soup_list, target_date, target_date)\n",
    "        print(sample_data.length)\n",
    "        if sample_data.length != 0:\n",
    "            is_soup_found = True\n",
    "    print()\n",
    "    compare = sample_data.compare(target_date, debug = True)\n",
    "    time_to_sleep = random.uniform(1, 3)\n",
    "    time.sleep(time_to_sleep)\n",
    "    if compare == 0:\n",
    "        return mid_page\n",
    "    elif compare == -1:\n",
    "        return do_binary_search_page(gall_name, mid_page+1, max_page, target_date)\n",
    "    else:\n",
    "        return do_binary_search_page(gall_name, min_page, mid_page-1, target_date)\n",
    "\n",
    "\n",
    "def set_start_end_page(gall_name, max_page, min_page, start_date, end_date):\n",
    "    get_start_date_page = do_binary_search_page(gall_name, min_page, max_page, start_date)\n",
    "    get_end_date_page = do_binary_search_page(gall_name, min_page, max_page, end_date)\n",
    "    return get_start_date_page, get_end_date_page\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterating:26\n",
      "https://gall.dcinside.com/mini/board/lists/?id=pumpitup&page=26\n",
      "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15\n",
      "2.752196879104025\n",
      "0\n",
      "https://gall.dcinside.com/mini/board/lists/?id=pumpitup&page=26\n",
      "Mozilla/5.0 (iPad; CPU OS 13_2_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.3 Mobile/15E148 Safari/604.1\n",
      "2.2404173640813996\n",
      "0\n",
      "https://gall.dcinside.com/mini/board/lists/?id=pumpitup&page=26\n",
      "Mozilla/5.0 (iPad; CPU OS 13_2_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.3 Mobile/15E148 Safari/604.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdo_binary_search_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://gall.dcinside.com/mini/board/lists/?id=pumpitup\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m52\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2024-03-31\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[27], line 22\u001b[0m, in \u001b[0;36mdo_binary_search_page\u001b[1;34m(gall_name, min_page, max_page, target_date)\u001b[0m\n\u001b[0;32m     20\u001b[0m is_soup_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(is_soup_found \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 22\u001b[0m     soup_list \u001b[38;5;241m=\u001b[39m \u001b[43mget_soup_list_from_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgall_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmid_page\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     sample_data \u001b[38;5;241m=\u001b[39m get_user_and_date_from_soup_list(soup_list, target_date, target_date)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sample_data\u001b[38;5;241m.\u001b[39mlength)\n",
      "Cell \u001b[1;32mIn[12], line 67\u001b[0m, in \u001b[0;36mget_soup_list_from_page\u001b[1;34m(gall_name, page_num)\u001b[0m\n\u001b[0;32m     65\u001b[0m url \u001b[38;5;241m=\u001b[39m construct_url(gall_name, page_num)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(url)\n\u001b[1;32m---> 67\u001b[0m request, soup \u001b[38;5;241m=\u001b[39m \u001b[43mextractSoupfromURL\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m soup_list \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m'\u001b[39m, class_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mub-content us-post\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m soup_list\n",
      "Cell \u001b[1;32mIn[18], line 25\u001b[0m, in \u001b[0;36mextractSoupfromURL\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     23\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(request\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m time_to_sleep \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_to_sleep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(time_to_sleep)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m request, soup\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "do_binary_search_page(\"https://gall.dcinside.com/mini/board/lists/?id=pumpitup\", 1, 52, '2024-03-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://gall.dcinside.com/mini/board/lists/?id=pumpitup&page=1680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], [], 0, '1999-01-01 00:00:00', '1999-01-01 00:00:00')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = construct_url(\"https://gall.dcinside.com/mini/board/lists/?id=pumpitup\", 1680)\n",
    "\n",
    "print(i)\n",
    "\n",
    "soup_blank = get_soup_list_from_page(\"https://gall.dcinside.com/mini/board/lists/?id=pumpitup\", 1680)\n",
    "\n",
    "get_user_and_date_from_soup_list(soup_blank, '2014-03-31', '2024-04-02')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': ['A', 'E', 'H', 'L'],\n",
       " '2': ['B', 'I'],\n",
       " '3': ['C', 'F', 'J', 'M'],\n",
       " '4': ['D', 'K'],\n",
       " '5': ['G', 'N']}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#고정닉 닉변 대응 용도\n",
    "def match_user_id_to_user_name(user_dict, user_list, user_id_list):\n",
    "    for i in range(len(user_list)):\n",
    "        if user_id_list[i] in user_dict:\n",
    "            if user_list[i] not in user_dict[user_id_list[i]]:\n",
    "                user_dict[user_id_list[i]].append(user_list[i])\n",
    "        else:\n",
    "            user_dict[user_id_list[i]] = [user_list[i]]\n",
    "    return user_dict\n",
    "\n",
    "users = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]\n",
    "user_id = [\"1\", \"2\", \"3\", \"4\", \"1\", \"3\", \"5\"]\n",
    "\n",
    "user_id_dict= {}\n",
    "\n",
    "user_dict_updated = match_user_id_to_user_name(user_id_dict, users, user_id)\n",
    "\n",
    "user2 = [\"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\"]\n",
    "user_id2 = [\"1\", \"2\", \"3\", \"4\", \"1\", \"3\", \"5\"]\n",
    "\n",
    "\n",
    "match_user_id_to_user_name(user_dict_updated, user2, user_id2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.845194638064627\n",
      "50\n",
      "2.430273848089227\n",
      "24\n",
      "2.6839733240909185\n",
      "11\n",
      "1.5811300152178827\n",
      "17\n",
      "2.0703910674937323\n",
      "14\n",
      "2.9662980535930554\n",
      "15\n",
      "1.696629885585466\n",
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "# Sleep for a random time between 1 to 3 seconds\n",
    "\n",
    "\n",
    "\n",
    "def do_binary_search(start, end, target):\n",
    "    if start > end:\n",
    "        return -1\n",
    "    mid = (start + end) // 2\n",
    "    time_to_sleep = random.uniform(1, 3)\n",
    "    time.sleep(time_to_sleep)\n",
    "    print(time_to_sleep)\n",
    "    print(mid)\n",
    "    if target == mid:\n",
    "        return mid\n",
    "    elif target < mid:\n",
    "        return do_binary_search(start, mid-1, target)\n",
    "    else:\n",
    "        return do_binary_search(mid+1, end, target) \n",
    "\n",
    "do_binary_search(0, 100, 16)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
